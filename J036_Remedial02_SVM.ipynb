{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "J036_Remedial02_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gtPCuQ9mxBz"
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "import scipy.optimize as opt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "JcnFFu-7mxCB"
      },
      "source": [
        "#Click here and press Shift+Enter\n",
        "!wget -O cell_samples.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/cell_samples.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "SOZljoGbmxCJ"
      },
      "source": [
        "### Load Data From CSV File  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "button": false,
        "new_sheet": false,
        "run_control": {
          "read_only": false
        },
        "id": "_sXlzXdumxCN"
      },
      "source": [
        "cell_df = pd.read_csv(\"cell_samples.csv\")\n",
        "cell_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FIe3PTrmxCY"
      },
      "source": [
        "ax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');\n",
        "cell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P2DqYcRmxCg"
      },
      "source": [
        "## Data pre-processing and selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XSHfbDUmxCm"
      },
      "source": [
        "cell_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2bCMMJamxCx"
      },
      "source": [
        "cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\n",
        "cell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\n",
        "cell_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO1APQD4mxC5"
      },
      "source": [
        "feature_df = cell_df[['Clump', 'UnifSize', 'UnifShape', 'MargAdh', 'SingEpiSize', 'BareNuc', 'BlandChrom', 'NormNucl', 'Mit']]\n",
        "X = np.asarray(feature_df)\n",
        "X[0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-LGzJl5mxDD"
      },
      "source": [
        "cell_df['Class'] = cell_df['Class'].astype('int')\n",
        "y = np.asarray(cell_df['Class'])\n",
        "y [0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPBLolQOmxDL"
      },
      "source": [
        "## Train/Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwcoCFfOmxDQ"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\n",
        "print ('Train set:', X_train.shape,  y_train.shape)\n",
        "print ('Test set:', X_test.shape,  y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbCe5pWlmxDX"
      },
      "source": [
        "<h2 id=\"modeling\">Modeling (SVM with Scikit-learn)</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLx9y_aKmxDc"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='rbf')\n",
        "clf.fit(X_train, y_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX0BVz57mxDo"
      },
      "source": [
        "yhat = clf.predict(X_test)\n",
        "yhat [0:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d45QscJqmxDv"
      },
      "source": [
        "<h2 id=\"evaluation\">Evaluation</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfeOgbblmxDy"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjFyFI0YmxD7"
      },
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6xIJsyNmxED"
      },
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])\n",
        "np.set_printoptions(precision=2)\n",
        "\n",
        "print (classification_report(y_test, yhat))\n",
        "\n",
        "# Plot non-normalized confusion matrix\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byaI8vWVmxEN"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_test, yhat, average='weighted') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwHNQFcgmxEX"
      },
      "source": [
        "Lets try jaccard index for accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnRGZL8omxEb"
      },
      "source": [
        "from sklearn.metrics import jaccard_similarity_score\n",
        "jaccard_similarity_score(y_test, yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olJ4jBOSmxE8"
      },
      "source": [
        "<h2 id=\"practice\">Practice</h2>\n",
        "Can you rebuild the model, but this time with a __linear__ kernel? You can use __kernel='linear'__ option, when you define the svm. How the accuracy changes with the new kernel function?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SndJ6B_bmxFA"
      },
      "source": [
        "    \n",
        "clf2 = svm.SVC(kernel='linear')\n",
        "clf2.fit(X_train, y_train) \n",
        "yhat2 = clf2.predict(X_test)\n",
        "print(\"Avg F1-score: %.4f\" % f1_score(y_test, yhat2, average='weighted'))\n",
        "print(\"Jaccard score: %.4f\" % jaccard_similarity_score(y_test, yhat2))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}